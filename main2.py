from dotenv import load_dotenv
import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_teddynote import logging
from prompts import Prompt

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from data import DBManager
from agent_config import AgentConfig

from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain_experimental.tools import PythonAstREPLTool
from langchain_core.output_parsers import StrOutputParser



# API KEY ì •ë³´ë¡œë“œ
load_dotenv()

# LangSmith ë¡œê¹…
logging.langsmith("KwaterGPT")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="KwaterGPT", page_icon="ğŸ’§")

# í˜ì´ì§€ ì œëª©
st.title("ìˆ˜ìì› GPT")

# ë²ˆìˆ˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state["messages"] = []

if "store" not in st.session_state:
    st.session_state["store"] = {}


# ì´ì „ ëŒ€í™” ì¶œë ¥
def print_message():
    for chat_message in st.session_state.messages:
        st.chat_message(chat_message.role).write(chat_message.content)


# ìƒˆë¡œìš´ ë©”ì‹œì§€ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


with st.sidebar:
    pass


# ë¬¸ì„œ í¬ë§·íŒ…
def format_doc(docs):
    return "\n\n".join([doc.page_content for doc in docs])


# 3. ì¶œë ¥ íŒŒì„œ - í…Œì´ë¸” ì´ë¦„ ì¶”ì¶œ í•¨ìˆ˜
def extract_tables(llm_response):
    """LLM ì‘ë‹µì—ì„œ í…Œì´ë¸” ì´ë¦„ ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""

    # 1. ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ì •ì˜
    AVAILABLE_TABLES = {
        "TB_C_RT": "ì‹¤ì‹œê°„ ì¸¡ì • ë°ì´í„° í…Œì´ë¸”. ì„¼ì„œì˜ ì‹¤ì‹œê°„ ì¸¡ì •ê°’ì„ ì €ì¥í•©ë‹ˆë‹¤.",
        "TB_AI_C_RT": "AI ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”. AIê°€ ë¶„ì„í•œ ì˜ˆì¸¡ê°’ê³¼ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.",
        "TB_AI_C_CTR": "AI ì œì–´ ê²°ê³¼ í…Œì´ë¸”. AIì˜ ì œì–´ ëª…ë ¹ê³¼ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.",
        "TB_TAG_MNG": "íƒœê·¸ ê´€ë¦¬ í…Œì´ë¸”. ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•˜ëŠ” íƒœê·¸(ì„¼ì„œ ë“±)ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."
    }

    tables = []
    for line in llm_response.split('\n'):
        if line.startswith("í…Œì´ë¸”:"):
            # ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ
            content = line.replace("í…Œì´ë¸”:", "").strip()
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í•­ëª©ì„ ë¶„ë¦¬
            if '[' in content and ']' in content:
                content = content.replace('[', '').replace(']', '')

            tables = [table.strip() for table in content.split(',')]
            break

    # ìœ íš¨í•œ í…Œì´ë¸”ë§Œ í•„í„°ë§
    valid_tables = [table for table in tables if table in AVAILABLE_TABLES]
    valid_tables.append("TB_TAG_MNG") if "TB_TAG_MNG" not in valid_tables else None
    return valid_tables


def db_research_agent(question: str):
    """
    DB ì—°êµ¬ ì—ì´ì „íŠ¸
    """
    conf = AgentConfig(
        location_code="A",
        plant_code="SN",
        algorithm_code="C"
    )
    dbm = DBManager(conf)
    db = dbm.get_db_connection()
    prompt = Prompt()

    # 2. í…Œì´ë¸” ì„ íƒ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
    table_selection_prompt = prompt.table_selection_prompt()
    llm = ChatOpenAI(model="gpt-4o", temperature=0)

    select_table_chain = table_selection_prompt | llm | StrOutputParser()

    response = select_table_chain.invoke({"question": question})
    selected_tables = extract_tables(response)
    
    TABLE_SCHEMAS = {
        table: db.get_table_info([table]) for table in selected_tables
    }

    prompt = Prompt()
    sql_query_gen_prompt = prompt.sql_query_gen_prompt(TABLE_SCHEMAS)
    sql_query_gen_chain = sql_query_gen_prompt | llm | StrOutputParser()

    query = sql_query_gen_chain.invoke({"question": question})

    result_df = dbm.select_from_table(query)

    python_repl = PythonAstREPLTool(
            globals={"pd": pd, "plt": plt, "np": np, "sns": sns, "df": result_df.copy()},  # í•„ìš”í•œ ëª¨ë“ˆë“¤ì„ globalsì— ì¶”ê°€
            locals=None
            # locals={"df": dataframe}  # ë°ì´í„°í”„ë ˆì„ì„ localsì— ì¶”ê°€
        )
    
    agent = create_pandas_dataframe_agent(
            llm,
            result_df,
            verbose=False,
            agent_type="tool-calling",
            allow_dangerous_code=True,
            extra_tools=[python_repl],
            prefix="You are a professional data analyst and expert in Pandas. "
            "You must use Pandas DataFrame(`df`) to answer user's request. "
            "\n\n[IMPORTANT] DO NOT create or overwrite the `df` variable in your code. \n\n"
            "You don't need to generate visualization code."
            "But if you are willing to generate visualization code, please use `plt.show()` at the end of your code. "
            "I prefer seaborn code for visualization, but you can use matplotlib as well."
            "\n\n<Visualization Preference>\n"
            "- [IMPORTANT] Use `English` for your visualization title and labels."
            "The language of final answer should be written in Korean. "
            "\n\n###\n\n<Column Guidelines>\n"
            "If user asks with columns that are not listed in `df.columns`, you may refer to the most similar columns listed below.\n"
        )

    return agent.invoke({"input": question})


print_message()

user_input = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
# warning_msg = st.empty()

if user_input:
    st.chat_message("user").write(user_input)

    response = db_research_agent(user_input)['output']
    st.chat_message("assistant").write(response)
    # with st.chat_message("assistant"):
    #     container = st.empty()

    #     # ì‘ë‹µ ì¶œë ¥
    #     ai_answer = ""
    #     for token in response:
    #         ai_answer += token
    #         container.markdown(ai_answer)

    # # ëŒ€í™”ê¸°ë¡ ì €ì¥
    # add_message("user", user_input)
    # add_message("assistant", ai_answer)